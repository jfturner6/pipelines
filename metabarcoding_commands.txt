##                  ##
## READ PREPARATION ##
##                  ##

### Run trimming on paired files in a loop. Assumes _R[12].fastq. ###
    # Get a list of unique samples. 

samples=$(for f in 0_demux/*.fastq; do s1=${f##*/}; echo ${s1%_*}; done | sort | uniq)
echo $samples 
    # If this looks right, proceed, if not you may need to tweak paths/names in previous command

mkdir 1_trimmed

# Do trimming, make sure that primers are right: -g is forward, -G is reverse primer. -j is threads, don't increase!

for s in $samples; do cutadapt -j 20 -g CCNGAYATRGCNTTYCCNCG -G TANACYTCNGGRTGNCCRAARAAYCA -o 1_trimmed/${s}_R1.fastq -p 1_trimmed/${s}_R2.fastq --discard-untrimmed 0_demux/${s}_R1.fastq 0_demux/${s}_R2.fastq; done

### Run merging on paired files in a loop. ###
  # Get a list of unique samples like above
samples=$(for f in 1_trimmed/*.fastq; do s1=${f##*/}; echo ${s1%_*}; done | sort | uniq)
echo $samples

mkdir 2_merged

  # Do merging
for s in $samples; do pear -f 1_trimmed/${s}_R1.fastq -r 1_trimmed/${s}_R2.fastq -o 2_merged/$s -q 26 -v 60 -j 20; done

  # Clean up uneeded files
cd 2_merged/
rm *discarded* *unassembled* 
rename -e "s/assembled\.//" *
cd ../

### Concatenating ###
  # Get a list of unique samples similar to above
samples=$(for f in 2_merged/*.fastq; do s1=${f##*/}; echo ${s1%.*}; done | sort | uniq)
echo $samples

  # Important note: change @D00 in the sed command for the start of the headers of your sequences (run head file.fastq). 
  # Try and use >=~4 characters to avoid quality lines starting with @ (rare, but it happens).

for s in $samples; do sed -e "s/\(^@D00.*\) .*$/\1;sample=$s;/" 2_merged/$s.fastq >> 3_mbc_concat.fastq; done

  # Note that if this fails, make sure to delete 3_mbc_concat.fastq before rerunning, as this command only ever appends to this file (>>)

##                     ##
## FILTERING AMPLICONS ##
##                     ##

### Quality filtering ###

vsearch --fastx_filter 3_mbc_concat.fastq --fastq_maxee 1 --fastaout 3_mbc_concat.fasta

### Dereplication ###

vsearch --derep_fulllength 3_mbc_concat.fasta --output 4_mbc_derep.fasta --sizeout --relabel uniq

  # Remember, the file 4_mbc_derep.fasta is important and will be used later!

### Denoising ###

vsearch --cluster_unoise 4_mbc_derep.fasta --minsize 4 --unoise_alpha 2 --centroids 5_mbc_denoise.fasta

### Length filtering ###

vsearch --fastx_filter 5_mbc_denoise.fasta --fastq_minlen 418 --fastq_maxlen 418 -fastaout 6_mbc_indelfil.fasta

### Translation filtering ##
  
  # Run the filtering (5 is the translation table)
filtertranslate.py 6_mbc_indelfil.fasta 5

  # Remove the ones that failed
rm *transfail.fa

  # Rename the file for those that passed
mv 6_mbc_indelfil_transpass.fa 7_mbc_transpass.fasta

### Chimera filtering ###

vsearch --uchime3_denovo 7_mbc_transpass.fasta --nonchimeras 8_mbc_final.fasta

  # 8_mbc_final.fasta contains your ASVs

##                  ##
## OTU DELIMITATION ##
##                  ##

### Standard delimitation method that we usually do ###

vsearch --cluster_size 8_mbc_final.fasta --sizein --relabel otu --id 0.97 --centroids otus.fasta

### SWARM alternative ###

swarm -w otus.fasta -d 1 -z 8_mbc_final.fasta

  # Don't bother with CROP

##                       ##
## MAPPING READS TO OTUS ##
##                       ##

  # Standard approach generating standard table
vsearch --usearch_global 3_mbc_concat.fasta -db otus.fasta -id 0.97 -otutabout reads_map.tsv

  # Alternative approach generating detailed searching output
vsearch --usearch_global 3_mbc_concat.fasta -db otus.fasta -id 0.97 -uc reads_search.uc

##                                ##
## MAPPING READS TO REFERENCE SET ##
##                                ##

  # Only useful if you don't expect to get or don't care about anything not in your reference set
vsearch --usearch_global 3_mbc_concat.fasta -db references.fasta -id 0.97 -otutabout reads_map_reference.tsv

##                     ##
## TAXONOMY ASSIGNMENT ##
##                     ##

  # Using BLASTn vs Genbank NT - the output from this would then be loaded into MEGAN
blastn -db <path to nt> -query otus.fasta -outfmt 5 -out otus_nt_blast.xml -num_threads 15 -evalue 0.001

  # Using BLASTn vs your own reference set
blastn -query otus.fasta -subject references.fasta -outfmt 6 -out otus_reference_blast.txt -num_threads 1 -evalue 0.001 -perc_identity 97

  # Using SINTAX vs the MIDORI dataset.
midorilocation="/av/references/MIDORI_LONGEST_20180221_COI_SINTAX.udb"
usearch110 -sintax otus.fasta -db $midorilocation -tabbedout otus_midori_sintax.tsv -strand both -sintax_cutoff 1

  # Filtering sequences based on a SINTAX output
filter_fasta_by_sintax.py -f otus.fasta -s otus_midori_sintax.tsv -t o:Coleoptera > otus_filtered.fasta
